{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MarksRNN_model1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+qMxtYhpnfrVqH4MjR+ZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinandan-Pal/MarkRNN/blob/master/MarksRNN_model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NunA2szM_e9i",
        "colab_type": "text"
      },
      "source": [
        "# **Importing and dowloading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxWIx2lfTJx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfFmg0wF_vXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/mahnazkoupaee/WikiHow-Dataset\n",
        "# Refer to this link to get the dataset used"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d059ubxPTUtC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e2e108fc-c34c-4415-96f2-013af182974e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJnvsigyTW9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filePath = \"drive/My Drive/MarksRNN/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN_CcOCyTZ8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "data = pd.read_csv(filePath + \"wikihowAll.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp8KFum_DVZp",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_feSgqTTlSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def newSent(Para,Score):\n",
        "    Para =  Para.replace(\"\\n\\n\", \"\\n\").replace(\"\\n\\n\\n\", \"\\n\")\n",
        "    sentences = Para.split('\\n')\n",
        "    newSents = \"\"\n",
        "    for sent in sentences:\n",
        "        if (random.random() < Score):\n",
        "            newSents = newSents + \"\\n\" + sent\n",
        "    return newSents"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YELG4BeXTmMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72c145dd-7c4b-4ea2-9e2c-daf070cf9c1a"
      },
      "source": [
        "newData = pd.DataFrame(columns = ['Answer', 'Marking','Score'])\n",
        "data[\"text\"]= data[\"text\"].astype(str)\n",
        "data[\"headline\"]= data[\"headline\"].astype(str)\n",
        "j = 0 \n",
        "#len(data)\n",
        "for i in range(999):\n",
        "    display.clear_output(wait=True)\n",
        "    print(str(i)+\"/\"+str(len(data)))\n",
        "    for score10 in range(5,11):\n",
        "        newData.loc[j] = [newSent(data['text'][i],score10/10) , data['headline'][i] , score10]\n",
        "        j = j + 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "998/215365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTaD1zLLTpHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(ans,mark):    \n",
        "    mark = mark.replace(\".,\",\".\")\n",
        "    ans = re.sub(r'[.]+[\\n]+[,]',\".\\n\", ans)\n",
        "    return ans,mark"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAOM76-yUDWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = []\n",
        "marking = []\n",
        "score = []\n",
        "\n",
        "for i in range(len(newData)):\n",
        "  if len(newData['Marking'][i] ) < (0.75*len(newData['Answer'][i])):\n",
        "    if( ( len(newData['Marking'][i])<2000 ) and ( len(newData['Answer'][i] )<4000) ):\n",
        "      a,b = preprocess(newData['Answer'][i],newData['Marking'][i])\n",
        "      \n",
        "      answer.append(a)\n",
        "      marking.append(b)\n",
        "\n",
        "      score.append([newData['Score'][i]])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjCmH7d-WQrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc697d6a-e446-4fd6-cc3c-d8a4f2809664"
      },
      "source": [
        "len(answer)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4422"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5re_mRhUyD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hohbXwTeU3x1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans_tensor , ans_token = tokenize(answer)\n",
        "mark_tensor , mark_token = tokenize(marking)\n",
        "score_tensor_train = tf.convert_to_tensor(score ,dtype=tf.float32)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDlVGp6_YMOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "12cbf674-6dd8-4476-bb37-718104a5db6e"
      },
      "source": [
        "print(ans_tensor.shape)\n",
        "print(mark_tensor.shape)\n",
        "print(score_tensor_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4422, 771)\n",
            "(4422, 246)\n",
            "tf.Tensor(\n",
            "[[ 5.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " ...\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [10.]], shape=(4422, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7hqg1zcaj7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL5c37Azasjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "556ef6fe-bb69-4b11-b362-31d098a65ec9"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(mark_token, mark_tensor[0])\n",
        "print ()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "215 ----> \n",
            "keep\n",
            "1766 ----> related\n",
            "575 ----> supplies\n",
            "9 ----> in\n",
            "3 ----> the\n",
            "197 ----> same\n",
            "1982 ----> area.\n",
            "make\n",
            "32 ----> an\n",
            "255 ----> effort\n",
            "2 ----> to\n",
            "220 ----> clean\n",
            "4 ----> a\n",
            "1983 ----> dedicated\n",
            "1984 ----> workspace\n",
            "153 ----> after\n",
            "160 ----> every\n",
            "1985 ----> session.\n",
            "place\n",
            "1118 ----> loose\n",
            "575 ----> supplies\n",
            "9 ----> in\n",
            "1986 ----> large,\n",
            "704 ----> clearly\n",
            "1987 ----> visible\n",
            "1988 ----> containers.\n",
            "use\n",
            "1989 ----> clotheslines\n",
            "6 ----> and\n",
            "1990 ----> clips\n",
            "2 ----> to\n",
            "136 ----> hang\n",
            "785 ----> sketches,\n",
            "1119 ----> photos,\n",
            "6 ----> and\n",
            "1120 ----> reference\n",
            "1991 ----> material.\n",
            "use\n",
            "160 ----> every\n",
            "1121 ----> inch\n",
            "8 ----> of\n",
            "3 ----> the\n",
            "862 ----> room\n",
            "10 ----> for\n",
            "1992 ----> storage,\n",
            "385 ----> especially\n",
            "1993 ----> vertical\n",
            "1994 ----> space.\n",
            "use\n",
            "1995 ----> chalkboard\n",
            "1996 ----> paint\n",
            "2 ----> to\n",
            "46 ----> make\n",
            "290 ----> space\n",
            "10 ----> for\n",
            "1997 ----> drafting\n",
            "1122 ----> ideas\n",
            "71 ----> right\n",
            "16 ----> on\n",
            "3 ----> the\n",
            "1998 ----> walls.\n",
            "purchase\n",
            "4 ----> a\n",
            "1999 ----> label\n",
            "2000 ----> maker\n",
            "2 ----> to\n",
            "46 ----> make\n",
            "1 ----> your\n",
            "1123 ----> organization\n",
            "2001 ----> strategy\n",
            "2002 ----> semi-permanent.\n",
            "make\n",
            "4 ----> a\n",
            "2003 ----> habit\n",
            "8 ----> of\n",
            "917 ----> throwing\n",
            "20 ----> out\n",
            "2004 ----> old,\n",
            "1902 ----> excess,\n",
            "15 ----> or\n",
            "2005 ----> useless\n",
            "363 ----> stuff\n",
            "126 ----> each\n",
            "2006 ----> month.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2a3huR9bUla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(ans_tensor)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(ans_tensor)//BATCH_SIZE\n",
        "\n",
        "#embedding_dim = 256\n",
        "#units = 1024\n",
        "\n",
        "vocab_ans_size = len(ans_token.word_index)+1\n",
        "vocab_mark_size = len(mark_token.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((ans_tensor,mark_tensor,score_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnrRLr6CeTcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "19374d16-1265-4f87-d66b-9aa4d03423fc"
      },
      "source": [
        "print(vocab_ans_size)\n",
        "print(vocab_mark_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32731\n",
            "8914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejR2RxzZeeXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8b46cab-1c78-4091-aeeb-57967a3be3d1"
      },
      "source": [
        "example_ans_batch, example_mark_batch , example_score = next(iter(dataset))\n",
        "example_ans_batch.shape, example_mark_batch.shape,example_score.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 771]), TensorShape([64, 246]), TensorShape([64, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7kyAsz0DjB1",
        "colab_type": "text"
      },
      "source": [
        "# **Setting up model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbvPNrZ0h5t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MRNN(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MRNN, self).__init__()\n",
        "    self.answer_hidden_net = tf.keras.Sequential(\n",
        "      [\n",
        "          #hub.KerasLayer(module_url),\n",
        "          tf.keras.layers.Embedding(vocab_ans_size, 64),\n",
        "          tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,return_sequences=True)),\n",
        "          tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "          tf.keras.layers.Dense(256, activation='relu'),\n",
        "          tf.keras.layers.Dropout(.2),\n",
        "          tf.keras.layers.Dense(512, activation='relu')\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    self.marking_hidden_net = tf.keras.Sequential(\n",
        "        [\n",
        "          #hub.KerasLayer(module_url),\n",
        "          tf.keras.layers.Embedding(vocab_mark_size, 64),\n",
        "          tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,return_sequences=True)),\n",
        "          tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "          tf.keras.layers.Dense(128, activation='relu'),\n",
        "          tf.keras.layers.Dropout(.2),\n",
        "          tf.keras.layers.Dense(256, activation='relu')\n",
        "        ]\n",
        "    )\n",
        "    self.score_output_net = tf.keras.Sequential(\n",
        "        [\n",
        "          tf.keras.layers.Dense(256, activation='relu'),\n",
        "          tf.keras.layers.Dropout(.2),\n",
        "          tf.keras.layers.Dense(128, activation='relu'),\n",
        "          tf.keras.layers.Dropout(.2),\n",
        "          tf.keras.layers.Dense(1)\n",
        "        ]\n",
        "    )\n",
        "  @tf.function\n",
        "  def encode_ans(self, x):\n",
        "    hidden_ans = self.answer_hidden_net(x)\n",
        "    #print(mean.shape)\n",
        "    return hidden_ans\n",
        "\n",
        "  def encode_mark(self, x):\n",
        "    hidden_mark = self.marking_hidden_net(x)\n",
        "    #print(mean.shape)\n",
        "    return hidden_mark\n",
        "  \n",
        "  def implement(self,ans,mark):\n",
        "    hidden_ans = self.answer_hidden_net(ans)\n",
        "    hidden_mark = self.marking_hidden_net(mark)\n",
        "    hidden_combined = tf.concat([hidden_ans, hidden_mark], 1)\n",
        "    predicted_score = self.score_output_net(hidden_combined)\n",
        "    return predicted_score\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRowcE5Rh99T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MRNN()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWUkziLIkJy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39b13a6f-04e5-4176-9293-f0917b248d3f"
      },
      "source": [
        "model.answer_hidden_net(example_ans_batch).shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtpMWKPdjFMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c7b1e41-72df-42c7-83d9-d2448e639830"
      },
      "source": [
        "model.marking_hidden_net(example_mark_batch).shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Pt7PQKlECM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_score_example = model.implement(example_ans_batch,example_mark_batch).shape"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBhx4gTemhCY",
        "colab_type": "text"
      },
      "source": [
        "# **IMPLEMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTwMFgucmIlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  loss_ = loss_object(real, pred)\n",
        "  return loss_ "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy8O7cbsnUtP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bdfd79e-4314-4593-9595-c8e9bed6a2d9"
      },
      "source": [
        "loss_eg = loss_function(example_score,predicted_score_example)\n",
        "loss_eg"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=1614>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YKJ4us8oVf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(ans, mark,score):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    predicted_score = model.implement(ans,mark)\n",
        "    loss = loss_function(score,predicted_score)\n",
        "\n",
        "\n",
        "  variables = model.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBuVyH2fzk8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f257a5e8-e43a-4577-e70f-e3c91ea39e6a"
      },
      "source": [
        "steps_per_epoch"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp1BN5OpoGPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "028e9c42-4e4e-4ef5-c694-9e5167a07152"
      },
      "source": [
        "EPOCHS = 2\n",
        "loss_history_train = []\n",
        "loss_history_val = []\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  total_loss = 0\n",
        "  set_loss = 0\n",
        "  for (batch, (ans, mark,score)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    if (batch % 10 == 0):\n",
        "      predicted_score = model.implement(ans,mark)\n",
        "      loss_val = loss_function(score,predicted_score)\n",
        "\n",
        "      model.answer_hidden_net.save_weights(\"answer_hidden_net_m.hdf5\")\n",
        "      model.marking_hidden_net.save_weights(\"marking_hidden_net.hdf5\")\n",
        "      model.score_output_net.save_weights(\"score_output_net.hdf5\")\n",
        "\n",
        "      \n",
        "      if(batch != 0):\n",
        "        loss_history_train.append(set_loss/9)\n",
        "        print('SAVING MODEL TRAIN RESULT: Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   set_loss/9))\n",
        "      set_loss = 0\n",
        "      print('VALIDATION RESULT: Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   loss_val.numpy()))\n",
        "      loss_history_val.append(loss_val.numpy())\n",
        "    else:\n",
        "      batch_loss = train_step(ans, mark,score)\n",
        "      total_loss += batch_loss\n",
        "      set_loss += batch_loss.numpy()\n",
        "      if batch % 1 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VALIDATION RESULT: Epoch 1 Batch 0 Loss 56.0613\n",
            "Epoch 1 Batch 1 Loss 61.3920\n",
            "Epoch 1 Batch 2 Loss 51.2119\n",
            "Epoch 1 Batch 3 Loss 47.4445\n",
            "Epoch 1 Batch 4 Loss 39.0388\n",
            "Epoch 1 Batch 5 Loss 9.1807\n",
            "Epoch 1 Batch 6 Loss 8.9053\n",
            "Epoch 1 Batch 7 Loss 5.1812\n",
            "Epoch 1 Batch 8 Loss 2.8317\n",
            "Epoch 1 Batch 9 Loss 3.2319\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 10 Loss 25.3798\n",
            "VALIDATION RESULT: Epoch 1 Batch 10 Loss 4.5899\n",
            "Epoch 1 Batch 11 Loss 5.0823\n",
            "Epoch 1 Batch 12 Loss 4.8432\n",
            "Epoch 1 Batch 13 Loss 3.1447\n",
            "Epoch 1 Batch 14 Loss 2.4876\n",
            "Epoch 1 Batch 15 Loss 3.3794\n",
            "Epoch 1 Batch 16 Loss 3.8059\n",
            "Epoch 1 Batch 17 Loss 3.0326\n",
            "Epoch 1 Batch 18 Loss 3.4277\n",
            "Epoch 1 Batch 19 Loss 2.9082\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 20 Loss 3.5680\n",
            "VALIDATION RESULT: Epoch 1 Batch 20 Loss 3.3968\n",
            "Epoch 1 Batch 21 Loss 2.6951\n",
            "Epoch 1 Batch 22 Loss 3.3838\n",
            "Epoch 1 Batch 23 Loss 2.6630\n",
            "Epoch 1 Batch 24 Loss 2.6595\n",
            "Epoch 1 Batch 25 Loss 2.9932\n",
            "Epoch 1 Batch 26 Loss 2.9478\n",
            "Epoch 1 Batch 27 Loss 3.1341\n",
            "Epoch 1 Batch 28 Loss 3.2742\n",
            "Epoch 1 Batch 29 Loss 3.0334\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 30 Loss 2.9760\n",
            "VALIDATION RESULT: Epoch 1 Batch 30 Loss 2.8104\n",
            "Epoch 1 Batch 31 Loss 2.9305\n",
            "Epoch 1 Batch 32 Loss 2.7289\n",
            "Epoch 1 Batch 33 Loss 3.5127\n",
            "Epoch 1 Batch 34 Loss 2.6772\n",
            "Epoch 1 Batch 35 Loss 2.6431\n",
            "Epoch 1 Batch 36 Loss 2.3717\n",
            "Epoch 1 Batch 37 Loss 2.9009\n",
            "Epoch 1 Batch 38 Loss 2.8360\n",
            "Epoch 1 Batch 39 Loss 3.1085\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 40 Loss 2.8566\n",
            "VALIDATION RESULT: Epoch 1 Batch 40 Loss 1.9184\n",
            "Epoch 1 Batch 41 Loss 3.0550\n",
            "Epoch 1 Batch 42 Loss 3.1592\n",
            "Epoch 1 Batch 43 Loss 3.3200\n",
            "Epoch 1 Batch 44 Loss 2.5627\n",
            "Epoch 1 Batch 45 Loss 3.0608\n",
            "Epoch 1 Batch 46 Loss 3.8097\n",
            "Epoch 1 Batch 47 Loss 2.8590\n",
            "Epoch 1 Batch 48 Loss 2.7286\n",
            "Epoch 1 Batch 49 Loss 2.6518\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 50 Loss 3.0230\n",
            "VALIDATION RESULT: Epoch 1 Batch 50 Loss 3.7640\n",
            "Epoch 1 Batch 51 Loss 2.6124\n",
            "Epoch 1 Batch 52 Loss 3.8516\n",
            "Epoch 1 Batch 53 Loss 2.9863\n",
            "Epoch 1 Batch 54 Loss 2.7668\n",
            "Epoch 1 Batch 55 Loss 3.2116\n",
            "Epoch 1 Batch 56 Loss 2.9875\n",
            "Epoch 1 Batch 57 Loss 3.7118\n",
            "Epoch 1 Batch 58 Loss 2.4402\n",
            "Epoch 1 Batch 59 Loss 3.0921\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 60 Loss 3.0734\n",
            "VALIDATION RESULT: Epoch 1 Batch 60 Loss 2.8311\n",
            "Epoch 1 Batch 61 Loss 3.0572\n",
            "Epoch 1 Batch 62 Loss 3.0427\n",
            "Epoch 1 Batch 63 Loss 3.0996\n",
            "Epoch 1 Batch 64 Loss 2.6560\n",
            "Epoch 1 Batch 65 Loss 3.0685\n",
            "Epoch 1 Batch 66 Loss 2.0919\n",
            "Epoch 1 Batch 67 Loss 3.1569\n",
            "Epoch 1 Batch 68 Loss 2.8335\n",
            "Epoch 1 Loss 5.6652\n",
            "Time taken for 1 epoch 996.4230213165283 sec\n",
            "\n",
            "VALIDATION RESULT: Epoch 2 Batch 0 Loss 2.9079\n",
            "Epoch 2 Batch 1 Loss 2.9659\n",
            "Epoch 2 Batch 2 Loss 3.0449\n",
            "Epoch 2 Batch 3 Loss 2.2830\n",
            "Epoch 2 Batch 4 Loss 2.4793\n",
            "Epoch 2 Batch 5 Loss 2.6464\n",
            "Epoch 2 Batch 6 Loss 2.6256\n",
            "Epoch 2 Batch 7 Loss 2.4740\n",
            "Epoch 2 Batch 8 Loss 2.7367\n",
            "Epoch 2 Batch 9 Loss 2.4454\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 10 Loss 2.6335\n",
            "VALIDATION RESULT: Epoch 2 Batch 10 Loss 2.2186\n",
            "Epoch 2 Batch 11 Loss 2.6022\n",
            "Epoch 2 Batch 12 Loss 3.0787\n",
            "Epoch 2 Batch 13 Loss 2.7550\n",
            "Epoch 2 Batch 14 Loss 2.5594\n",
            "Epoch 2 Batch 15 Loss 2.2600\n",
            "Epoch 2 Batch 16 Loss 2.5964\n",
            "Epoch 2 Batch 17 Loss 2.4709\n",
            "Epoch 2 Batch 18 Loss 2.7202\n",
            "Epoch 2 Batch 19 Loss 2.2329\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 20 Loss 2.5862\n",
            "VALIDATION RESULT: Epoch 2 Batch 20 Loss 2.4416\n",
            "Epoch 2 Batch 21 Loss 2.5358\n",
            "Epoch 2 Batch 22 Loss 2.7925\n",
            "Epoch 2 Batch 23 Loss 2.6291\n",
            "Epoch 2 Batch 24 Loss 2.4256\n",
            "Epoch 2 Batch 25 Loss 2.6326\n",
            "Epoch 2 Batch 26 Loss 2.5048\n",
            "Epoch 2 Batch 27 Loss 2.3651\n",
            "Epoch 2 Batch 28 Loss 3.6606\n",
            "Epoch 2 Batch 29 Loss 2.7345\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 30 Loss 2.6978\n",
            "VALIDATION RESULT: Epoch 2 Batch 30 Loss 2.5588\n",
            "Epoch 2 Batch 31 Loss 2.6138\n",
            "Epoch 2 Batch 32 Loss 2.5656\n",
            "Epoch 2 Batch 33 Loss 2.4856\n",
            "Epoch 2 Batch 34 Loss 2.5656\n",
            "Epoch 2 Batch 35 Loss 2.9280\n",
            "Epoch 2 Batch 36 Loss 2.1201\n",
            "Epoch 2 Batch 37 Loss 2.9702\n",
            "Epoch 2 Batch 38 Loss 3.2165\n",
            "Epoch 2 Batch 39 Loss 2.7770\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 40 Loss 2.6936\n",
            "VALIDATION RESULT: Epoch 2 Batch 40 Loss 2.0966\n",
            "Epoch 2 Batch 41 Loss 2.5361\n",
            "Epoch 2 Batch 42 Loss 1.9249\n",
            "Epoch 2 Batch 43 Loss 3.3806\n",
            "Epoch 2 Batch 44 Loss 3.0018\n",
            "Epoch 2 Batch 45 Loss 2.4470\n",
            "Epoch 2 Batch 46 Loss 2.6415\n",
            "Epoch 2 Batch 47 Loss 3.1794\n",
            "Epoch 2 Batch 48 Loss 2.6033\n",
            "Epoch 2 Batch 49 Loss 2.2737\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 50 Loss 2.6654\n",
            "VALIDATION RESULT: Epoch 2 Batch 50 Loss 2.9720\n",
            "Epoch 2 Batch 51 Loss 2.3559\n",
            "Epoch 2 Batch 52 Loss 3.0334\n",
            "Epoch 2 Batch 53 Loss 2.5046\n",
            "Epoch 2 Batch 54 Loss 3.1051\n",
            "Epoch 2 Batch 55 Loss 2.9902\n",
            "Epoch 2 Batch 56 Loss 2.6336\n",
            "Epoch 2 Batch 57 Loss 2.7421\n",
            "Epoch 2 Batch 58 Loss 2.4155\n",
            "Epoch 2 Batch 59 Loss 2.3379\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 60 Loss 2.6798\n",
            "VALIDATION RESULT: Epoch 2 Batch 60 Loss 2.9429\n",
            "Epoch 2 Batch 61 Loss 2.8827\n",
            "Epoch 2 Batch 62 Loss 3.5320\n",
            "Epoch 2 Batch 63 Loss 1.9472\n",
            "Epoch 2 Batch 64 Loss 2.4722\n",
            "Epoch 2 Batch 65 Loss 2.8161\n",
            "Epoch 2 Batch 66 Loss 2.8048\n",
            "Epoch 2 Batch 67 Loss 2.6476\n",
            "Epoch 2 Batch 68 Loss 2.0860\n",
            "Epoch 2 Loss 2.3883\n",
            "Time taken for 1 epoch 992.3292243480682 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXEPteMYsJdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "34eee179-467a-42f6-9199-a96b348324cf"
      },
      "source": [
        "plt.plot(loss_history_train,label=\"Train\")# Blue\n",
        "plt.plot(loss_history_val,label=\"Validation\")# Yellow \n",
        "plt.show"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZMPRX_YBE6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.answer_hidden_net.load_weights(\"answer_hidden_net_m.hdf5\")\n",
        "model.marking_hidden_net.load_weights(\"marking_hidden_net.hdf5\")\n",
        "model.score_output_net.load_weights(\"score_output_net.hdf5\")"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}