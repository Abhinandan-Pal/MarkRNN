{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MarksRNN_model2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvbj1d5E2ePthV59z+LJqg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinandan-Pal/MarkRNN/blob/master/MarksRNN_model2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NunA2szM_e9i",
        "colab_type": "text"
      },
      "source": [
        "# **Importing and dowloading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxWIx2lfTJx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfFmg0wF_vXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/mahnazkoupaee/WikiHow-Dataset\n",
        "# Refer to this link to get the dataset used"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d059ubxPTUtC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78ceb6b4-f13f-46f9-867f-2aa0eed48c52"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"drive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJnvsigyTW9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filePath = \"drive/My Drive/MarksRNN/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN_CcOCyTZ8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "data = pd.read_csv(filePath + \"wikihowAll.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp8KFum_DVZp",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_feSgqTTlSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def newSent(Para,Score):\n",
        "    Para =  Para.replace(\"\\n\\n\", \"\\n\").replace(\"\\n\\n\\n\", \"\\n\")\n",
        "    sentences = Para.split('\\n')\n",
        "    newSents = \"\"\n",
        "    for sent in sentences:\n",
        "        if (random.random() < Score):\n",
        "            newSents = newSents + \"\\n\" + sent\n",
        "    return newSents"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YELG4BeXTmMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1264a08-f343-49ff-9928-b57cade0609e"
      },
      "source": [
        "newData = pd.DataFrame(columns = ['Answer', 'Marking','Score'])\n",
        "data[\"text\"]= data[\"text\"].astype(str)\n",
        "data[\"headline\"]= data[\"headline\"].astype(str)\n",
        "j = 0 \n",
        "#len(data)\n",
        "for i in range(999):\n",
        "    display.clear_output(wait=True)\n",
        "    print(str(i)+\"/\"+str(len(data)))\n",
        "    for score10 in range(5,11):\n",
        "        newData.loc[j] = [newSent(data['text'][i],score10/10) , data['headline'][i] , score10]\n",
        "        j = j + 1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "998/215365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTaD1zLLTpHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(ans,mark):    \n",
        "    mark = mark.replace(\".,\",\".\")\n",
        "    ans = re.sub(r'[.]+[\\n]+[,]',\".\\n\", ans)\n",
        "    return ans,mark"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAOM76-yUDWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = []\n",
        "marking = []\n",
        "score = []\n",
        "\n",
        "for i in range(len(newData)):\n",
        "  if len(newData['Marking'][i] ) < (0.75*len(newData['Answer'][i])):\n",
        "    if( ( len(newData['Marking'][i])<2000 ) and ( len(newData['Answer'][i] )<4000) ):\n",
        "      a,b = preprocess(newData['Answer'][i],newData['Marking'][i])\n",
        "      \n",
        "      answer.append(a)\n",
        "      marking.append(b)\n",
        "\n",
        "      score.append([newData['Score'][i]])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjCmH7d-WQrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b67cc9a-53f2-4748-dc79-98c95300d025"
      },
      "source": [
        "len(answer)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4408"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5re_mRhUyD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hohbXwTeU3x1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans_tensor , ans_token = tokenize(answer)\n",
        "mark_tensor , mark_token = tokenize(marking)\n",
        "score_tensor_train = tf.convert_to_tensor(score ,dtype=tf.float32)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDlVGp6_YMOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "dc14a6d7-ad2a-471a-da82-aebf1fee9fd0"
      },
      "source": [
        "print(ans_tensor.shape)\n",
        "print(mark_tensor.shape)\n",
        "print(score_tensor_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4408, 769)\n",
            "(4408, 246)\n",
            "tf.Tensor(\n",
            "[[ 5.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " ...\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [10.]], shape=(4408, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7hqg1zcaj7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL5c37Azasjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c09c809-af0b-48f1-9ad1-e3e839e3cc21"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(mark_token, mark_tensor[0])\n",
        "print ()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "208 ----> \n",
            "keep\n",
            "1749 ----> related\n",
            "547 ----> supplies\n",
            "9 ----> in\n",
            "3 ----> the\n",
            "209 ----> same\n",
            "1989 ----> area.\n",
            "make\n",
            "32 ----> an\n",
            "268 ----> effort\n",
            "2 ----> to\n",
            "212 ----> clean\n",
            "4 ----> a\n",
            "1990 ----> dedicated\n",
            "1991 ----> workspace\n",
            "150 ----> after\n",
            "158 ----> every\n",
            "1992 ----> session.\n",
            "place\n",
            "1111 ----> loose\n",
            "547 ----> supplies\n",
            "9 ----> in\n",
            "1993 ----> large,\n",
            "686 ----> clearly\n",
            "1994 ----> visible\n",
            "1995 ----> containers.\n",
            "use\n",
            "1996 ----> clotheslines\n",
            "6 ----> and\n",
            "1997 ----> clips\n",
            "2 ----> to\n",
            "135 ----> hang\n",
            "787 ----> sketches,\n",
            "1112 ----> photos,\n",
            "6 ----> and\n",
            "1113 ----> reference\n",
            "1998 ----> material.\n",
            "use\n",
            "158 ----> every\n",
            "1114 ----> inch\n",
            "8 ----> of\n",
            "3 ----> the\n",
            "873 ----> room\n",
            "10 ----> for\n",
            "1999 ----> storage,\n",
            "391 ----> especially\n",
            "2000 ----> vertical\n",
            "2001 ----> space.\n",
            "use\n",
            "2002 ----> chalkboard\n",
            "2003 ----> paint\n",
            "2 ----> to\n",
            "44 ----> make\n",
            "307 ----> space\n",
            "10 ----> for\n",
            "2004 ----> drafting\n",
            "1115 ----> ideas\n",
            "72 ----> right\n",
            "16 ----> on\n",
            "3 ----> the\n",
            "2005 ----> walls.\n",
            "purchase\n",
            "4 ----> a\n",
            "2006 ----> label\n",
            "2007 ----> maker\n",
            "2 ----> to\n",
            "44 ----> make\n",
            "1 ----> your\n",
            "1116 ----> organization\n",
            "2008 ----> strategy\n",
            "2009 ----> semi-permanent.\n",
            "make\n",
            "4 ----> a\n",
            "2010 ----> habit\n",
            "8 ----> of\n",
            "962 ----> throwing\n",
            "20 ----> out\n",
            "2011 ----> old,\n",
            "2012 ----> excess,\n",
            "14 ----> or\n",
            "2013 ----> useless\n",
            "372 ----> stuff\n",
            "127 ----> each\n",
            "2014 ----> month.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2a3huR9bUla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(ans_tensor)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(ans_tensor)//BATCH_SIZE\n",
        "\n",
        "vocab_ans_size = len(ans_token.word_index)+1\n",
        "vocab_mark_size = len(mark_token.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((ans_tensor,mark_tensor,score_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnrRLr6CeTcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5dcc7a0a-0aab-4fa0-a3df-6b8a719d0f16"
      },
      "source": [
        "print(vocab_ans_size)\n",
        "print(vocab_mark_size)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32602\n",
            "8964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejR2RxzZeeXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a818bf5-139c-4230-fa63-e8c78e2f2aa8"
      },
      "source": [
        "example_ans_batch, example_mark_batch , example_score = next(iter(dataset))\n",
        "example_ans_batch.shape, example_mark_batch.shape,example_score.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 769]), TensorShape([64, 246]), TensorShape([64, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7kyAsz0DjB1",
        "colab_type": "text"
      },
      "source": [
        "# **Setting up model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_7S57mYrhjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderMark(tf.keras.Model):\n",
        "  def __init__(self,batch_sz):\n",
        "    super(EncoderMark, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = 256\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_mark_size, 256)\n",
        "    self.lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.enc_units))\n",
        "    self.dense = tf.keras.layers.Dense(256, activation='relu')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.lstm1(x)# initial_state = hidden\n",
        "    output = self.dense(x)\n",
        "    return output#, state\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DULnIg9uyu7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderAns(tf.keras.Model):\n",
        "  def __init__(self,batch_sz):\n",
        "    super(DecoderAns, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = 256\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_ans_size, 256)\n",
        "    self.lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.enc_units))\n",
        "    self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "    self.dense2 = tf.keras.layers.Dense(1, activation='relu')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    encoder_out = tf.expand_dims(hidden, axis=1)\n",
        "    encoder_out = tf.repeat(encoder_out, repeats=[x.shape[1]], axis=1)\n",
        "    x = tf.concat([x, encoder_out], 2)\n",
        "    x = self.lstm1(x)# initial_state = hidden\n",
        "    x = self.dense1(x)\n",
        "    output = self.dense2(x)\n",
        "\n",
        "    return output#, state\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOg2JYwmtwW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = EncoderMark(BATCH_SIZE)\n",
        "\n",
        "encoder_out = encoder.call(example_mark_batch)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIqlor3BBgEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b02dc0b1-e5c4-4194-fd00-d2ae420c6957"
      },
      "source": [
        "example_ans_batch.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 769])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxgb0yMrAEpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = DecoderAns(BATCH_SIZE)\n",
        "decoder_out = decoder.call(example_ans_batch,encoder_out)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWQH7kBlDMp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24352c7c-5a31-4adc-9c61-83636b0e0720"
      },
      "source": [
        "decoder_out.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g42n2pM44C9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_out = tf.expand_dims(encoder_out, axis=1)\n",
        "encoder_out = tf.repeat(encoder_out, repeats=[766], axis=1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW-AtsfvXbTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbe47b02-5956-4429-ee16-d2061672f503"
      },
      "source": [
        "encoder_out[1,2,1] == encoder_out[1,3,1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgsrBP_92Tv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "837f38f2-157e-44bb-9556-559d7c1888e9"
      },
      "source": [
        "embedding = tf.keras.layers.Embedding(vocab_ans_size, 64)\n",
        "inp1 = embedding(example_ans_batch)\n",
        "inp1.shape[1]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBhx4gTemhCY",
        "colab_type": "text"
      },
      "source": [
        "# **IMPLEMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTwMFgucmIlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "loss_object = tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  loss_ = loss_object(real, pred)\n",
        "  return loss_ "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YKJ4us8oVf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(ans, mark,score):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    encoder_out = encoder.call(mark)\n",
        "    predicted_score = decoder.call(ans,encoder_out)\n",
        "    loss = loss_function(score,predicted_score)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBuVyH2fzk8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b97bc757-e548-44e1-9981-9f3031af3e09"
      },
      "source": [
        "steps_per_epoch"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BTajEIAFvfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder.save_weights(\"encoder_mark.hdf5\")\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VClFo3aOh2R3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_history_train = []\n",
        "loss_history_val = []"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp1BN5OpoGPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1e3f736-e7d5-4c0c-a6f3-292366192f4c"
      },
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  total_loss = 0\n",
        "  set_loss = 0\n",
        "  for (batch, (ans, mark,score)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    if (batch % 10 == 0):\n",
        "      encoder_out = encoder.call(mark)\n",
        "      predicted_score = decoder.call(ans,encoder_out)\n",
        "      loss_val = loss_function(score,predicted_score)\n",
        "\n",
        "      encoder.save_weights(\"encoder_mark.hdf5\")\n",
        "      decoder.save_weights(\"decoder_ans.hdf5\")\n",
        "\n",
        "      \n",
        "      if(batch != 0):\n",
        "        loss_history_train.append(set_loss/9)\n",
        "        print('SAVING MODEL TRAIN RESULT: Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   set_loss/9))\n",
        "      set_loss = 0\n",
        "      print('VALIDATION RESULT: Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   loss_val.numpy()))\n",
        "      loss_history_val.append(loss_val.numpy())\n",
        "    else:\n",
        "      batch_loss = train_step(ans, mark,score)\n",
        "      total_loss += batch_loss\n",
        "      set_loss += batch_loss.numpy()\n",
        "      if batch % 1 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / (steps_per_epoch*.9)))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VALIDATION RESULT: Epoch 1 Batch 0 Loss 2.7946\n",
            "Epoch 1 Batch 1 Loss 2.5458\n",
            "Epoch 1 Batch 2 Loss 2.7237\n",
            "Epoch 1 Batch 3 Loss 2.8520\n",
            "Epoch 1 Batch 4 Loss 2.3226\n",
            "Epoch 1 Batch 5 Loss 3.0617\n",
            "Epoch 1 Batch 6 Loss 2.4138\n",
            "Epoch 1 Batch 7 Loss 3.3585\n",
            "Epoch 1 Batch 8 Loss 2.4166\n",
            "Epoch 1 Batch 9 Loss 2.6466\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 10 Loss 2.7046\n",
            "VALIDATION RESULT: Epoch 1 Batch 10 Loss 2.5548\n",
            "Epoch 1 Batch 11 Loss 3.1044\n",
            "Epoch 1 Batch 12 Loss 2.7742\n",
            "Epoch 1 Batch 13 Loss 3.8480\n",
            "Epoch 1 Batch 14 Loss 3.1060\n",
            "Epoch 1 Batch 15 Loss 2.8256\n",
            "Epoch 1 Batch 16 Loss 2.1832\n",
            "Epoch 1 Batch 17 Loss 3.2475\n",
            "Epoch 1 Batch 18 Loss 2.8342\n",
            "Epoch 1 Batch 19 Loss 3.3171\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 20 Loss 3.0267\n",
            "VALIDATION RESULT: Epoch 1 Batch 20 Loss 2.4033\n",
            "Epoch 1 Batch 21 Loss 3.0102\n",
            "Epoch 1 Batch 22 Loss 3.3079\n",
            "Epoch 1 Batch 23 Loss 2.6688\n",
            "Epoch 1 Batch 24 Loss 3.2168\n",
            "Epoch 1 Batch 25 Loss 2.5939\n",
            "Epoch 1 Batch 26 Loss 3.1093\n",
            "Epoch 1 Batch 27 Loss 2.5890\n",
            "Epoch 1 Batch 28 Loss 2.8699\n",
            "Epoch 1 Batch 29 Loss 3.2081\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 30 Loss 2.9527\n",
            "VALIDATION RESULT: Epoch 1 Batch 30 Loss 3.4427\n",
            "Epoch 1 Batch 31 Loss 3.2493\n",
            "Epoch 1 Batch 32 Loss 3.4060\n",
            "Epoch 1 Batch 33 Loss 2.1757\n",
            "Epoch 1 Batch 34 Loss 2.8275\n",
            "Epoch 1 Batch 35 Loss 2.6189\n",
            "Epoch 1 Batch 36 Loss 2.7278\n",
            "Epoch 1 Batch 37 Loss 3.6409\n",
            "Epoch 1 Batch 38 Loss 3.0955\n",
            "Epoch 1 Batch 39 Loss 2.7352\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 40 Loss 2.9419\n",
            "VALIDATION RESULT: Epoch 1 Batch 40 Loss 2.9725\n",
            "Epoch 1 Batch 41 Loss 3.0914\n",
            "Epoch 1 Batch 42 Loss 2.6899\n",
            "Epoch 1 Batch 43 Loss 3.4420\n",
            "Epoch 1 Batch 44 Loss 3.4244\n",
            "Epoch 1 Batch 45 Loss 2.7425\n",
            "Epoch 1 Batch 46 Loss 4.0043\n",
            "Epoch 1 Batch 47 Loss 3.1450\n",
            "Epoch 1 Batch 48 Loss 2.8944\n",
            "Epoch 1 Batch 49 Loss 3.5323\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 50 Loss 3.2185\n",
            "VALIDATION RESULT: Epoch 1 Batch 50 Loss 2.5687\n",
            "Epoch 1 Batch 51 Loss 2.8975\n",
            "Epoch 1 Batch 52 Loss 3.0141\n",
            "Epoch 1 Batch 53 Loss 2.9412\n",
            "Epoch 1 Batch 54 Loss 2.8044\n",
            "Epoch 1 Batch 55 Loss 2.8496\n",
            "Epoch 1 Batch 56 Loss 2.9079\n",
            "Epoch 1 Batch 57 Loss 2.6059\n",
            "Epoch 1 Batch 58 Loss 2.8257\n",
            "Epoch 1 Batch 59 Loss 2.6852\n",
            "SAVING MODEL TRAIN RESULT: Epoch 1 Batch 60 Loss 2.8368\n",
            "VALIDATION RESULT: Epoch 1 Batch 60 Loss 2.9108\n",
            "Epoch 1 Batch 61 Loss 2.5522\n",
            "Epoch 1 Batch 62 Loss 2.8397\n",
            "Epoch 1 Batch 63 Loss 2.8766\n",
            "Epoch 1 Batch 64 Loss 2.6399\n",
            "Epoch 1 Batch 65 Loss 3.2460\n",
            "Epoch 1 Batch 66 Loss 2.7128\n",
            "Epoch 1 Batch 67 Loss 3.0501\n",
            "Epoch 1 Loss 2.9256\n",
            "Time taken for 1 epoch 45.27365493774414 sec\n",
            "\n",
            "VALIDATION RESULT: Epoch 2 Batch 0 Loss 3.2792\n",
            "Epoch 2 Batch 1 Loss 2.6970\n",
            "Epoch 2 Batch 2 Loss 2.4802\n",
            "Epoch 2 Batch 3 Loss 2.9496\n",
            "Epoch 2 Batch 4 Loss 2.5482\n",
            "Epoch 2 Batch 5 Loss 3.3080\n",
            "Epoch 2 Batch 6 Loss 2.4918\n",
            "Epoch 2 Batch 7 Loss 3.0148\n",
            "Epoch 2 Batch 8 Loss 3.3032\n",
            "Epoch 2 Batch 9 Loss 2.9718\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 10 Loss 2.8627\n",
            "VALIDATION RESULT: Epoch 2 Batch 10 Loss 2.6111\n",
            "Epoch 2 Batch 11 Loss 2.9224\n",
            "Epoch 2 Batch 12 Loss 2.7969\n",
            "Epoch 2 Batch 13 Loss 2.9621\n",
            "Epoch 2 Batch 14 Loss 2.4024\n",
            "Epoch 2 Batch 15 Loss 3.3551\n",
            "Epoch 2 Batch 16 Loss 2.7322\n",
            "Epoch 2 Batch 17 Loss 2.6413\n",
            "Epoch 2 Batch 18 Loss 3.1690\n",
            "Epoch 2 Batch 19 Loss 2.9019\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 20 Loss 2.8759\n",
            "VALIDATION RESULT: Epoch 2 Batch 20 Loss 2.5406\n",
            "Epoch 2 Batch 21 Loss 3.1542\n",
            "Epoch 2 Batch 22 Loss 2.8892\n",
            "Epoch 2 Batch 23 Loss 2.7282\n",
            "Epoch 2 Batch 24 Loss 3.3182\n",
            "Epoch 2 Batch 25 Loss 2.9540\n",
            "Epoch 2 Batch 26 Loss 2.1893\n",
            "Epoch 2 Batch 27 Loss 3.3264\n",
            "Epoch 2 Batch 28 Loss 2.4242\n",
            "Epoch 2 Batch 29 Loss 3.1510\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 30 Loss 2.9039\n",
            "VALIDATION RESULT: Epoch 2 Batch 30 Loss 2.8620\n",
            "Epoch 2 Batch 31 Loss 3.0044\n",
            "Epoch 2 Batch 32 Loss 2.8125\n",
            "Epoch 2 Batch 33 Loss 3.4473\n",
            "Epoch 2 Batch 34 Loss 3.1851\n",
            "Epoch 2 Batch 35 Loss 2.5968\n",
            "Epoch 2 Batch 36 Loss 3.2236\n",
            "Epoch 2 Batch 37 Loss 3.1692\n",
            "Epoch 2 Batch 38 Loss 3.5312\n",
            "Epoch 2 Batch 39 Loss 2.5755\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 40 Loss 3.0606\n",
            "VALIDATION RESULT: Epoch 2 Batch 40 Loss 2.1715\n",
            "Epoch 2 Batch 41 Loss 3.3898\n",
            "Epoch 2 Batch 42 Loss 3.1844\n",
            "Epoch 2 Batch 43 Loss 3.0291\n",
            "Epoch 2 Batch 44 Loss 2.9211\n",
            "Epoch 2 Batch 45 Loss 2.8822\n",
            "Epoch 2 Batch 46 Loss 2.7242\n",
            "Epoch 2 Batch 47 Loss 2.7353\n",
            "Epoch 2 Batch 48 Loss 3.2141\n",
            "Epoch 2 Batch 49 Loss 2.9530\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 50 Loss 3.0037\n",
            "VALIDATION RESULT: Epoch 2 Batch 50 Loss 3.2711\n",
            "Epoch 2 Batch 51 Loss 2.3030\n",
            "Epoch 2 Batch 52 Loss 2.6696\n",
            "Epoch 2 Batch 53 Loss 3.4311\n",
            "Epoch 2 Batch 54 Loss 3.3141\n",
            "Epoch 2 Batch 55 Loss 2.6806\n",
            "Epoch 2 Batch 56 Loss 2.7693\n",
            "Epoch 2 Batch 57 Loss 2.5745\n",
            "Epoch 2 Batch 58 Loss 3.0204\n",
            "Epoch 2 Batch 59 Loss 3.3635\n",
            "SAVING MODEL TRAIN RESULT: Epoch 2 Batch 60 Loss 2.9029\n",
            "VALIDATION RESULT: Epoch 2 Batch 60 Loss 3.0984\n",
            "Epoch 2 Batch 61 Loss 2.2983\n",
            "Epoch 2 Batch 62 Loss 3.0037\n",
            "Epoch 2 Batch 63 Loss 2.4675\n",
            "Epoch 2 Batch 64 Loss 3.4368\n",
            "Epoch 2 Batch 65 Loss 2.6349\n",
            "Epoch 2 Batch 66 Loss 3.3380\n",
            "Epoch 2 Batch 67 Loss 2.8049\n",
            "Epoch 2 Loss 2.9162\n",
            "Time taken for 1 epoch 44.98663353919983 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXEPteMYsJdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "53b7304a-9e31-403c-d14c-17e046dc2079"
      },
      "source": [
        "plt.plot(loss_history_train[10:],label=\"Train\")# Blue\n",
        "plt.plot(loss_history_val[10:],label=\"Validation\")# Yellow \n",
        "plt.xlabel(\"10 batch\")\n",
        "plt.ylabel(\"MSE loss\")\n",
        "plt.title(\"Loss For 999 orginal data points\")\n",
        "plt.savefig('Both_model2_999.pdf')  \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gc1dX48e/ZVe+SJctFsuXeC8bddJtiAoEkQEI1LfAmkJA3JEB68r4kIXlDQvJLJUAwJZTQQyeAARt3XHDB3XK3JNuSJdmqe35/zAiEUbO9s/V8nmeenZ2dvffMrnTm7p2ZO6KqGGOMiR++cAdgjDEmtCzxG2NMnLHEb4wxccYSvzHGxBlL/MYYE2cs8RtjTJyxxG9MEInIKyIyKwjlnCYiO45i/Tkicv3x1us1EVktIqeFO454Z4k/BojIVhGZEYZ6HxSRBhGpaTV9OUhlny8iq9wy3xeR4a1eSxaR34nILhE5ICJ/FpHEVq8PE5G3RKRKRDaKyBeCEVNXqOpMVZ0dqvqORbj+XgBUdYSqzunKuuGMM9ZZ4jfH69eqmtFqeuJo3iwiCW0sGwQ8CvwXkAP8G3ih1bp3AOOBkcBgYBzww1blPQ+8COQBNwCPiMjgY9m4zmI1JhpZ4o9hbsv4HrdlvMudT3ZfyxeRF0WkUkT2i8h7IuJzX7tdRHaKSLWIrBOR6cdQ91fd1vZ+EXlBRHq1ek1F5CYR2QBsaOPtZwPvqepcVW0CfgX0Bk51Xz8f+IOq7lfVcuAPwLXua0OBXsDvVLVZVd8C5gFXthOnT0R+KCKlIlImIg+JSLb7Wokb63Uisg14S0T8InK3iFSIyBYRudldJ8F9z8ddLiJytYjMFZHfuL9MtojIzFZ1XyMia93PebOI3HgUn++ZIvKR+6vmj4C0em2A+4tnnxvnoyKS4772MNAH+Lf7a+o2d/m/RGSPW967IjKig7rniMgvRWSRiBwUkedFJK/V6593u3Qq3XWHtXrt41a8iPxURJ50P/Nq9z3j24tTRFJE5BF3uypFZLGIFHb1MzOfsMQf234ATAbGAmOAibgtY+BWYAdQABQC3wdURIYANwMTVDUTJwlvPZpKReQM4JfAJUBPoBR4/IjVLgQmAcNpmxwxLzgt/PZeL2pJ2O2UNbKd1652p9OB/kAG8Mcj1jkVGIbzWXwVmInzmY5zt6Mjk4B1QD7wa+B+EWmJvQw4D8gCrgF+JyLjOikPEckHnsH5LvOBTcC01qvgfP693LiLgZ8CqOqVwDbgfPcX2q/d97wCDAK6Ax/g/OLqyFU4O9ueQBPOzhf3l9VjwLdw/rZexkneSe2U83mcv40c4AXcz76dOGcB2e72dMP5RXi4kzhNW1TVpiifcBLzjDaWbwLObfX8bGCrO/8/OF0iA494z0CchDQDSOyk3geBOqDSnSrc5ffjdAG1rJcBNAIl7nMFzuig3KFALXAakAT8CAgA33NfvxOnFV8A9AAWumX2BBKBzcBt7vxZQAPwWjt1vQl8vdXzIW6sCUCJW27/Vq+/BdzY6vkMd50E9/kc4Hp3/mpgY6t109x1e7QTy3PALe78acCOdta7CljQ6rng7MSvb2f9C4Flnf29tHo9x40zu53X5wB3tXo+3P2M/e539WSr13zATuC0I+vG2Rn954hyDrcXJ86O5n1gdLj/56J9shZ/bOuF09puUeouA/g/YCPwutvNcAeAqm7Eaa39FCgTkcdbd9O04TeqmuNO+W3Vq6o1wD6c7poW29srUFU/wmnd/RHYjdOqXYOT3AB+DiwDluMkgudwkvVeVW3ESXSfA/bg/LJ5stV7j9TWZ5SA8yuorVh7HfG83e1w7Wm1XYfc2QwAEZkpIgvc7rBK4Fx3WzvzqRjUyYofPxeRQvd72ykiB4FHOirX7b66S0Q2uetvdV/qKJbW212Ks5PN57PffcBdtzdt29Nq/hCQIu0fS3kYeA143O26/LW0Oqhvus4Sf2zbBfRt9byPuwxVrVbVW1W1P87P7W+39OWr6j9V9ST3vYrTx37M9YpIOs5P852t1ulwWFhVfUpVR6pqN+AnOK3vxe5rh1X1ZlXt7ca/D1jqJhlUdaWqnqqq3VT1bJwunEVdiRXnM2oC9rYT626gqNXz4o62oz3iHGt5GvgNUKiqOTjdItLhGz+J4eN63a6j1nH8wo15lKpmAVccUe6Rn/1lwAU4v16ycT5rOomldX19cHa8FXz2u2+JbSdH71Nxqmqjqv5MVYcDU3G6ya46hnLjniX+2JHoHvxqmRJw+lp/KCIFbr/wj3Faf4jIeSIy0P3HrAKagYCIDBGRM9zEVIfThxo4ylgeA64RkbFuOb8AFqrq1q4WICInui3RAuBe4AX3lwAi0ltEeoljMk73wk9avXe0+xmkich3cLqAHuwg1v8WkX4ikuHG+oQ6B5Xb8iRwixtDDnB7V7fpCElAMlAONLkHfc/q4ntfAkaIyBfd7/mbOF1eLTKBGqBKRHoD3z3i/Xtxdoat16/H2YGm4XwGnblCRIaLSBpOt+FTqtqM8/l8TkSmu63xW92y3+/itrUbp4icLiKjRMQPHMTZ2Rzt36bBEn8seRknSbdMP8XpC18CrAQ+xDlod6e7/iDgPzgJYj7wZ1V9GycZ3YXTetuDc7Dve0cTiKr+BycZP43TOh0AfOUot+f3OMcN1gEHcA6qthiAk0hqgdnAHar6eqvXr3TrLQOmA2eqan079TyA04XwLrAFZ2f3jQ7i+jvwOs5nugznc2/C2XF2mapW4yTsJ3G27zKcg5tdeW8FcDHO97QP57uc12qVn+EceK7C2Uk8c0QRv8RpEFS6O8aHcLpnduJ0qS3oQhgP4+xM9wAp7ragqutwfmH8P5y/ofNxDtA2dGXbOomzB/AUTtJfC7zjxmGOkrgHTYwxx8Btqf9VVft2unKMEJE5wCOqel+4YzHHxlr8xhwFEUkVkXNFJMHtRvkJ8Gy44zLmaFjiN+boCE5XygGcrp61OMdOjIka1tVjjDFxxlr8xhgTZ6Ji0Kn8/HwtKSkJdxjGGBNVli5dWqGqBUcuj4rEX1JSwpIlS8IdhjHGRBURKW1ruXX1GGNMnLHEb4wxccYSvzHGxBlL/MYYE2cs8RtjTJyxxG+MMXHGEr8xxsSZ2E78q56BJQ+EOwpjjIkosZ341zwPb/0cmhvDHYkxxkSM2E78Yy6FQxWw8c1wR2KMMREjthP/wOmQlg8rHgt3JMYYEzFiO/H7E2HURbDuFThcGe5ojDEmIsR24gcY8xVoroc1z4U7EmOMiQixn/h7joX8IbDi8XBHYowxESH2E7+I0+rfNh/2bwl3NMYYE3axn/gBRl8CCKx8MtyRGGNM2Hma+EVkq4h8KCLLRWSJuyxPRN4QkQ3uY66XMQCQXQT9TnbO7rF7DBtj4lwoWvynq+pYVR3vPr8DeFNVBwFvus+9N+ZSOLAFti8KSXXGGBOpwtHVcwEw252fDVwYklqHnQ+JabDSDvIaY+Kb14lfgddFZKmI3OAuK1TV3e78HqCwrTeKyA0iskRElpSXlx9/JMmZMPQ8WPU0NNUff3nGGBOlvE78J6nqOGAmcJOInNL6RVVVnJ3DZ6jqvao6XlXHFxR85ibxx2bMV6CuCta/GpzyjDEmCnma+FV1p/tYBjwLTAT2ikhPAPexzMsYPqX/aZDRA1Y8EbIqjTEm0niW+EUkXUQyW+aBs4BVwAvALHe1WcDzXsXwGT4/jL4YNrwGtftCVq0xxkQSL1v8hcBcEVkBLAJeUtVXgbuAM0VkAzDDfR46Yy6FQJPT12+MMXEowauCVXUzMKaN5fuA6V7V26nCEdBjlHN2z6QbOl/fGGNiTHxcuXuk0V+BnUuhfH24IzHGmJCLz8Q/6mIQn53Tb4yJS/GZ+DMLYcB0Z+yeQCDc0RhjTEjFZ+IH55z+qu1QOi/ckRhjTEjFb+Ifci4kZdo4/caYuBO/iT8pDUZcAGueh4ZD4Y7GGGNCJn4TPzhn9zRUw7qXwx2JMcaETHwn/r7TILvYGaffGGPiRHwnfp/PuTvXpregem+4ozHGmJCI78QPTnePBuBDuy2jMSY+WOIvGAzFk2DxfdDcFO5ojDHGc5b4AaZ+Aw5shbUvhDsSY4zxXEwn/r/M2cQvX17b+YpDzoW8AfD+H+xm7MaYmBfTiX9P1WH+9u5m3t9U0fGKPj9MvRl2LYOtc0MTnDHGhElMJ/7bZw6lpFsatz21kpr6Tvrvx1wKaflOq98YY2JYTCf+tKQE7r5kDLsqD/Pzlzrp8klMhUn/BRteh71rQhOgMcaEQUwnfoAT++bx1VP689iibcxZ18ntfSdcB4lp8P7/C01wxhgTBjGf+AH+e8ZgBhdmcPvTK6k61Nj+iml5cMKV8OG/4OCu0AVojDEhFBeJPyXRz90Xj2VfTQM//ffqjlee8nXQZljwl9AEZ4wxIRYXiR9gVFE2N58xkGeX7eTVVbvbXzG3BIZfCEsfhLqqUIVnjDEhEzeJH+Cm0wcysncWP3h2FRU19e2vOO2bUH/QSf7GGBNj4irxJ/p93H3xWKrrmvjhs6vQ9i7W6nUC9DsFFvwVmhpCG6QxxngsrhI/wJAemXz7rMG8unoPzy/v4ADu1Fugeheseip0wRljTAjEXeIH+OrJ/RnXJ4cfP7+KPVV1ba80cDp0H+Gc2mnDOBhjYkhcJn6/T7j7krE0NAe4/emVbXf5iDiDt5WtgY3/CX2QxhjjkbhM/AD98tP53sxhvLO+nMcXb297pZFfgsxeMO/3oQ3OGGM8FLeJH+DKyX2ZOqAbd764hu3727jhekISTP4abH0Pdn4Q+gCNMcYDcZ34fT7h1xeNBuD3b25oe6UTr4bkLBu8zRgTM+I68QMU5aZx2tDuvLehvO2+/pQsGH8NrHke9m8JfYDGGBNkcZ/4AaYNyGfvwXo2lde2vcKkr4H4Yf6fQhuYMcZ4wPPELyJ+EVkmIi+6z/uJyEIR2SgiT4hIktcxdGbawG4A7d+wJasnjL4Elj0C1XtDGJkxxgRfKFr8twCtB8P/FfA7VR0IHACuC0EMHeqTl0bvnFTmbezgTl1TvwHN9XDPSHjoAqf1X77ezvE3xkQdTxO/iBQBnwPuc58LcAbQcjnsbOBCL2PoChFh2sBuzN+0j+ZAO4m8+zC47j8w6Uao3gOvfR/+NAF+PwZe+g6sfx0a2jgzyBhjIkyCx+XfA9wGZLrPuwGVqtpyH8QdQO+23igiNwA3APTp08fjMGHawHyeXLKD1buqGF2U0/ZKRSc601l3woFS2PgGbPgPLH8UFv8dElKg5CQYeh6MmwU+O4RijIk8nmUmETkPKFPVpcfyflW9V1XHq+r4goKCIEf3WVMGOP388zbu69obcvvChOvhssfhti1wxTNw4jXOmT8vfgtWP+NhtMYYc+y8bJJOAz4vIluBx3G6eH4P5IhIyy+NImCnhzF0WffMFAYXZrR/gLcjiSnO2D4z74Kbl0B2H1j+z+AHaYwxQeBZ4lfV76lqkaqWAF8B3lLVy4G3gYvc1WYBz3sVw9GaOiCfxVv3U9/UfOyF+Hww5suw+W042MENX4wxJkzC0Ql9O/BtEdmI0+d/fxhiaNO0gfnUNQb4oLTy+AoacyloAFY+EZzAjDEmiEKS+FV1jqqe585vVtWJqjpQVS9W1Q5uhRVak/rn4ZMOzufvqm4DoHgSrHjMTvc0xkQcO+2klayUREYX5XR8Pn9XjbkUyj+CXcuOvyxjjAkiS/xHmDawGyt2VFFd13h8BY34AviTnVa/McZEEEv8R5g2IJ/mgLJoy/7jKyg1B4Z+Dj58yu7ba4yJKJb4jzCuby7JCb6un8/fkbGXweH9sOG14y/LGGOCxBL/EVIS/YwvyT3+A7wA/U+HjEJYbt09xpjIYYm/DVMH5PPRnmoqao7zhCN/gjOq54bXoDYIOxJjjAkCS/xtmDYwH4D3NwWhu2fMZRBocvr6jTEmAljib8Oo3tlkpiTwfjBO6ywcDj3HOAO5GWNMBLDE3wa/T5jcvxvzgtHPD06rf89K2Ls6OOUZY8xxsMTfjmkDurF9/2G27w/CGPujLgJfgg3cZoyJCJb429HSzx+Uq3jT82HQ2bDySWhu6nx9Y4zxkCX+dgzsnkH3zGTmBeMAL8DYS6G2DDa9FZzyjDHmGFnib4eIMHVAN+ZvqkCDMdDaoLMhNQ9WWHePMSa8LPF3YOrAfCpqGli3t/r4C0tIcvr6P3oZDh84/vKMMeYYWeLvwCf9/EHq7hlzKTTXw+png1OeMcYcA0v8Heidk0pJt7TgnM8P0OsEKBhqQzgYY8LKEn8npg7MZ+GW/TQ1B46/MBGn1b9jEVRsPP7yjDHmGFji78S0AfnU1DexYkdVcAoc/WUQn43Tb4wJG0v8nZgyoBtA8Lp7sno6o3aufAICQfgVYYwxR8kSfyfy0pMY3jMreMM3gDNOf9V22Ppe8Mo0xpgussTfBdMGduOD0koONzQHp8Chn4PkLOvuMcaEhSX+Lpg6MJ+G5gBLSo/zdowtElNhxIWw5gU7p98YE3KW+LtgYkkeCT4J3vn8ABNvhMZamPeH4JVpjDFdcFSJX0R8IpLlVTCRKj05gRP65ATndowteoyEkRfBwr9C9d7glWuMMZ3oNPGLyD9FJEtE0oFVwBoR+a73oUWWqQPy+XBnFVWHGoNX6Onfh6Z6ePf/glemMcZ0oist/uGqehC4EHgF6Adc6WlUEWjawHxUCW6rv9sAGHclLH0QDmwNXrnGGNOBriT+RBFJxEn8L6hqIxCE4Sqjywl9csjPSOaJJduDW/Cpt4PPD3PuCm65xhjTjq4k/r8BW4F04F0R6Qsc9DKoSJTo9zFrSl/mrCtnQzBG62yR1QsmfhVWPA5la4NXrjHGtKPTxK+qf1DV3qp6rjpKgdNDEFvEuXxyX5ITfNw/d0twCz7p25CcCW/dGdxyjTGmDV05uHuLe3BXROR+EfkAOCMEsUWcvPQkvnRiEc8s20lFTX3wCk7Lg6nfgI9ehB1LgleuMca0oStdPde6B3fPAnJxDux22iEtIikiskhEVojIahH5mbu8n4gsFJGNIvKEiCQd1xaE2LXT+tHQFOCRBaXBLXjy1yAtH978n+CWa4wxR+hK4hf38VzgYVVd3WpZR+qBM1R1DDAWOEdEJgO/An6nqgOBA8B1Rx92+AzsnsH0od15eH4pdY1BGsIBnK6ek2+FLe/A5jnBK9cYY47QlcS/VERex0n8r4lIJtDpsJLu8YAa92miOylON9FT7vLZOGcLRZXrTu7HvtoGnlu2M7gFj78WsoqcVn8w7vNrjDFt6Erivw64A5igqoeAJOCarhQuIn4RWQ6UAW8Am4BKVW1yV9kB9G7nvTeIyBIRWVJeXt6V6kJmSv9uDO+ZxX1ztwTnRuwtElPgtDtg51Knv98YYzzQlbN6AkAR8EMR+Q0wVVVXdqVwVW1W1bHu+ycCQ7samKreq6rjVXV8QUFBV98WEiLC9Sf3Y2NZDe+sD/JOacylkD/YOcMnEMSuJGOMcXXlrJ67gFuANe70TRH5xdFUoqqVwNvAFCBHRBLcl4qAIPeXhMZ5o3tRmJXMfe8F+dROfwKc/gMo/whWPhncso0xhq519ZwLnKmqD6jqA8A5wHmdvUlECkQkx51PBc4E1uLsAC5yV5sFPH8sgYdbUoKPWVNLmLuxgrW7g3w92/ALoOdYmPMLaGoIbtnGmLjX1dE5c1rNZ3fxPT2Bt0VkJbAYeENVXwRuB74tIhuBbsD9XQ020lw2sQ+pif7gX9AlAtN/DJXbnHF8jDEmiBI6X4VfAstE5G2c0zhPwTnY2yH3OMAJbSzfjNPfH/Vy0pK4eHwRjy3axm1nD6F7VkrwCh9wBvQ9yRm584TLISk9eGUbY+JaVw7uPgZMBp4BngamqOoTXgcWLa6d1o+mgPLQ/CBf0CUCM34CtWWw4C/BLdsYE9faTfwiMq5lwum22eFOvdxlBijJT+fMYYU8srA0ePfkbVE8EQbPhPf/H9TXdL6+McZ0QUddPXd38FrLhVgGuP7k/ry+Zi9Pf7CDKyb3DW7hJ38b7j8Tlj8Kk24MbtnGmLjUbuJX1bgcgfNYTCjJZXRRNg/M3cJlE/vg83VlRIsuKp4IxZNg/p9gwvXO2P3GGHMc7GbrQSAiXHdSPzZX1PLWR2XBr2DqN6CyFNb+O/hlG2PijiX+IDl3VE96Zadw39zNwS98yLmQ28/p67cxfIwxx8kSf5Ak+n1cPa2EBZv3s2pnVXAL9/lhyk2wcwlsXxjcso0xcaejs3quaDU/7YjXbvYyqGj15Ql9SE/y4IIugLGXQ2qu0+o3xpjj0FGL/9ut5o/MNtd6EEvUy05N5JIJxfx7xS52Vx0ObuFJac7B3Y9egn2bglu2MSaudJT4pZ35tp4b17XT+hFQ5cH3twa/8AlfBX+ic4aPMcYco44Sv7Yz39Zz4yrOS2PmyJ78c+E2auqbOn/D0cgshNFfhuX/hNp9wS3bGBM3Okr8Q0VkpYh82Gq+5fmQEMUXla4/uR/VdU08sXh78AufcjM0HYYlUTu2nTEmzDq6cndYyKKIMSf0yWViSR4PzN3CrCl9SfAH8eSp7kNh0Fmw6F6Y+k3nrl3GGHMU2s1IqlraegJqgHFAvvvcdOD6k/uxs/IwL6/aE/zCp34DasthpY2VZ4w5eh2dzvmiiIx053sCq3DO5nlYRL4Vovii1oxhhfTLT+fv724O7n15AUpOhh6jYf4fIdDpfe+NMeZTOuqD6Keqq9z5a3BupHI+MAk7nbNTPp9zX94Pd1axcMv+4BYu4nTzVKyHjW8Et2xjTMzrKPE3tpqfDrwMoKrVgDUzu+BL44rIS0/i7+96MIzDiAshq7dd0GWMOWodJf7tIvINEfkCTt/+q/Dx/XMTQxFctEtJ9HPl5L68+VEZG8uCPJ6+PxEmfw22vge7lgW3bGNMTOso8V8HjACuBr6sqpXu8snAPzyOK2ZcOaUvyQk+7vdi8LZxsyA5C97/Y/DLNsbErI7O6ilT1f9S1QtU9fVWy99W1d+EJrzol5+RzBfHFfH0Bzspr64PbuEpWTDuKlj9LFR6cM2AMSYmdXRWzwsdTaEMMtpdf3I/GpoCPLzAg7NgJ3/NOdi78K/BL9sYE5M6uoBrCrAdeAxYiI3Pc8wGFGQwY1ghD8/fytdOHUBqUhDvopVdBCO+AEtnw6m3QUp28Mo2xsSkjvr4ewDfB0YCvwfOBCpU9R1VfScUwcWSr57cjwOHGnn6gx3BL3zKzdBQDUsfDH7ZxpiY01Eff7Oqvqqqs3AO6G4E5thY/MdmYr88xhRlc//cLTQHgnxBV6+x0P90eO+3UFsR3LKNMTGnw0FkRCRZRL4IPALcBPwBeDYUgcUaEeGrp/RnS0Ut/1m7N/gVnHMXNNTAGz8OftnGmJjS0cHdh4D5OOfw/0xVJ6jq/6rqzpBFF2POGdGD3jmp3PeeB6d2dh/qdPksfxRK3w9++caYmNFRi/8KYBBwC/C+iBx0p2oRORia8GJLgt/HdSf1Y/HWA3yw7UDwKzj1NsguhpduhebGztc3xsSljvr4faqa6U5ZraZMVc0KZZCx5JIJxWSlJHjT6k9Kh5m/grI1sOAvwS/fGBMTgjhQvOmKjOQELpvUl1dX7WHbvkPBr2Do52DwTJhzF1R5cAaRMSbqWeIPg6unluD3CQ/M2+JNBTN/BRqAV+/wpnxjTFTzLPGLSLGIvC0ia0RktYjc4i7PE5E3RGSD+5jrVQyRqkd2Cp8f05snFm+n6pAHffG5feHU78Laf8P61ztf3xgTV7xs8TcBt6rqcJzrAG4SkeHAHcCbqjoIeNN9HneuPamEw43N/GupR2PsTPkG5A+GV74LjYe9qcMYE5U8S/yqultVP3Dnq4G1QG/gAmC2u9ps4EKvYohkI3plM6Ekl4fmlxII9gVdAAlJ8Lm74cBW58IuY4xxhaSPX0RKgBNwxvwpVNXd7kt7gMJ23nODiCwRkSXl5eWhCDPkrppSwrb9h3hnvUfb1+8UGP1lmHcPVGz0pg5jTNTxPPGLSAbwNPAtVf3U+f/q3Iy2zeauqt6rquNVdXxBQYHXYYbFOSN70D0zmQff3+pdJWfdCQmp8PKtEOx7/xpjopKniV9EEnGS/qOq+oy7eK978/aWm7iXeRlDJEv0+7h8Ul/eWV/OlopabyrJ6A7TfwSb58Cqp72pwxgTVbw8q0eA+4G1qtq6k/kFYJY7Pwt43qsYosGlk4pJ9AsPz/dgrP4W46+FXifAa9+Huirv6jHGRAUvW/zTgCuBM0RkuTudC9wFnCkiG4AZ7vO41T0zhXNH9eRfS7ZTW9/kTSU+P3zut1BTBm//wps6jDFRw8uzeuaqqqjqaFUd604vq+o+VZ2uqoNUdYaq7vcqhmhx1ZQSquubeHaZh+Pf9R4HE66DRffC7hXe1WOMiXh25W4EGNcnh5G9s3ho/lbUywOwZ/wIUnKc4RyMMXHLEn8EEBFmTSlh/d4a5m/e511FqTkw4XpY9wrs2+RdPcaYiGaJP0KcP6YXuWmJPPS+hwd5wUn8vgS7ObsxccwSf4RISfTzlYl9eH3NHnZWejjEQmYhjLoIlj0Khyu9q8cYE7Es8UeQyyf1AeDRBR63+id/HRpr4YPZna9rjIk5lvgjSFFuGjOGFfL44u3UNTZ7V1HP0VByMiy8F5o9OoXUGBOxLPFHmKunlrC/toGXVu7ufOXjMfnrcHAHrI3r6+eMiUuW+CPMlAHdGNg9g9nzPT61c/A5kNcf5v/ZuzqMMRHJEn+EcU7t7MvKHVUs3+7hwVefDyZ9DXYuge2LvKvHGBNxLPFHoC+OKyIzOYGHvBy/B2DsZZCSDQus1W9MPLHEH4HSkxP40olFvLhyF+XV9d5VlJwB42bBmheg0qM7gRljIo4l/gh11ZS+NDYrjy/a5m1FE29wHhf9zdt6jDERwxJ/hOpfkMEpgwt4dOE2GpsD3lWUUwzDPw9LH4L6Gu/qMcZEDEv8EWzWlL7sOVjH66v3elvR5JugvgqWP+ptPcaYiGCJP4KdNqQ7ffLS+Me8Ld6e2lk8AYomwIK/QMDDC0zyTNwAABTJSURBVMeMMRHBEn8E8/uE60/ux5LSA8zx6obsLSZ/HQ5sgfWveluPMSbsLPFHuK9M6EPfbmn86pWPaA542Oof9nnILrYLuoyJA5b4I1xSgo/bzh7KR3uqeeaDHd5V5E9wzvApnWt36DImxlnijwLnjurBmOIcfvvGem8Hbxt3FSSmW6vfmBhniT8KiAjfmzmU3VV1/GPeVu8qSs2BE66AVU9D9R7v6jHGhJUl/igxuX83pg/tzp/nbORAbYN3FU26EQJNsPg+7+owxoSVJf4ocvvModTWN/HHtzd6V0m3ATBkJix5ABo9vBOYMSZsLPFHkcGFmVx8YjEPzy9l+/5D3lU05SY4tA+WPeJdHcaYsLHEH2X++8zB+Hxw9+vrvKuk7zQomghz74EmDweJM8aEhSX+KNMjO4XrTurHc8t3sWpnlTeViMBptzt36LJhHIyJOZb4o9CNpw4gNy2RX76y1ruhHAZMh97j4b3fQpOHB5ONMSFniT8KZaUk8s3pg5i3cR/vbqjwphIROO0OqNoOK/7pTR3GmLCwxB+lLp/Ulz55adzl5VAOA2dAr3Hw3t3Q3OhNHcaYkLPEH6WSEnx85+whrN19kOeW7fSmkpZWf+U2WPGYN3UYY0LOEn8UO29UT0YXZXP36+u8G8ph0FnQ6wR49zfW6jcmRniW+EXkAREpE5FVrZblicgbIrLBfcz1qv544PMJd8wcyq6qOma/v9WbSkTg1NuhshRWPuFNHcaYkPKyxf8gcM4Ry+4A3lTVQcCb7nNzHKYOyOf0IQX86e2NVB7y6OybwedAzzFuq7/JmzqMMSHjWeJX1XeB/UcsvgCY7c7PBi70qv54cvvMoVTXN/HHtzwayqGl1X9gC3z4pDd1GGNCJtR9/IWqutud3wMUtreiiNwgIktEZEl5ucd3n4pyQ3tkcfGJRcyev5UtFbXeVDLkXOgxCt79P2v1GxPlwnZwV50rj9o9D1FV71XV8ao6vqCgIISRRafvnD2EJL+Pn7+01psKWlr9+zfDqqe8qcMYExKhTvx7RaQngPtYFuL6Y1b3zBRuOmMg/1m7l7leXdQ15HNQONJp9dtN2Y2JWqFO/C8As9z5WcDzIa4/pl07rR/Fean8z4uraWoOBL8Cnw9OvQ32bXRu1mKMiUpens75GDAfGCIiO0TkOuAu4EwR2QDMcJ+bIElJ9PODc4exfm8Njy3a5k0lQ8+H7sPhnV9bq9+YKOXlWT2XqmpPVU1U1SJVvV9V96nqdFUdpKozVPXIs37McTp7RA8m98/jt2+sp+qQBxdcfdzq3wCrnw1++cYYz9mVuzFGRPjxeSOoOtzIPW+u96aSYRdAwTBr9RsTpSzxx6DhvbL48oQ+PDy/lI1lNcGvwOeDU78LFetgzXPBL98Y4ylL/DHq1rMGk5ro586X1nhTwfALIX+I2+r34ECyMcYzlvhjVH5GMt+cPog568p5e50HZ836/M7IneUfOcM2G2OihiX+GDZragn98tO588U1NHpxeueIL8Coi2HOL2DzO8Ev3xjjCUv8MSwpwccPzh3GpvJaHp5fGvwKROC8e6DbIHj6Oji4u/P3GGPCzhJ/jJs+rDsnD8rnnv+sZ3+tB6N3JmfAJQ9BQ62T/G0cH2MiniX+GCci/Oi84dQ2NPO7Nzw6vbP7UKflXzoP3vpfb+owxgSNJf44MLgwk8sn9eHRhaWs21PtTSVjvgwnXg3z7oF1r3pThzEmKCzxx4n/njGYzJRE/vfFNTgDo3rgnF9Bj9Hw7I1wwINjCsaYoLDEHydy05P41oxBzN1YwSur9nhTSWIKXDIbVOFfs6Cp3pt6jDHHxRJ/HLlicl9G9s7iO/9awYrtld5UktcfLvwT7FoGr/3AmzqMMcfFEn8cSfT7eODqCXTLSOKaBxd7d7euYefDlJth8d9t+GZjIpAl/jjTPTOF2ddMBOCqBxZSVl3nTUUzfgrFk+CFb0LFBm/qMMYcE0v8cah/QQb/uHoCFdUNXP3AYqrrPBi+2Z8IF/0DEpLhyaug4VDw6zDGHBNL/HFqTHEOf7liHOv3VnPjw0upb/JgeOXs3vDFv0PZWnjua1BTHvw6jDFHzRJ/HDttSHd+fdFo3t+0j1ufXEEg4MFpngOnw/QfOcM3/24EPHcT7Pkw+PUYY7osIdwBmPD64rgiyqrrueuVjyjITObH5w1HRIJbycm3OrdsXPhXWPEYLH8ESk6GSf8FQ2Y6I30aY0LGWvyGG0/pz7XT+vGPeVv527ubvamkYDCc91v49ho483/hwFZ44nL4wwkw/09QV+VNvcaYzxDPruIMovHjx+uSJUvCHUZMCwSUW55Yzr9X7OLui8fwpROLvK2wuQnWvQQL/gLb5kNSBoy9HE64HApHRs6vAFXQAASaQHzOQetYVrEBljwAe1c5t9fsMcqZCoY6F+iFW2Md1JZDVm/nTnDRqnafE39ytqfbISJLVXX8kcutq8cA4PMJv7l4NPtr67nt6ZXkZSRx+pDun1qnsTnAofpmahqaqK1voqbeeaytb3YeG9pb1owAffLS6NstjT55aZTkp9Nn0HmkDL/AudhrwV+dhLPob5CUCUUnOqeDFk2EovGQmhOcDW2qh4r1sHeNk9z2rnZuHN9U7yT3QJNzH+GP5z8ZbVR9idT3GE9jySkE+p2Gv2gcSYlJJPrlmLvHGpoC7D1Yx56DdeyqPMyeqjp2V9U5jwfr2FtVR05aIv0L0umfn0H/gnT65afTvyCD7NQg7YSam2Ddy7D4PtjyDvgSoXA4LHsEGt1rPcQPBUM+2RH0GAWFoyC926eKUlXqmwIcPNzIwbpGqg43cbCuEVUl0e9rNcnH80l+Hwnu89QkP6l+xV+1DfZtgv2bYN9GZ37fJqjaDiik5UP/U6H/ac6U0yc4n4WXAgHY9KbT2Nn0prtQICUbUnOdv/HUXEjJ+fTzMZdCen5QQ7EWv/mU6rpGvnLvAjaV11DSLZ3aBieJ19Q30dDUtZu5+ATSkxPISE4gLclPRnICzaps23eIg3WfHra5MCuZvt3S6ZuXxtDMwww59AHdDiyn4MAK8mrW4yOAIpSn9GN7+gi2pI5kU8oIahLySPRDsl9IFCUxQUj0QbIPEn2Q4IcUmshv2EnBoQ3k1mwgs2odKVWbEDeZqz8JKRgCBUNp8KVQ2wgHG5ypqj5AVZ1yoC7AgboAh5uEbKlhqm81I6QUnygHNY35geHMDYxikYxid0JvkhISSPQLPndHIOJOiPvojJgqwMG6JipqPjusRWZyAj2yU+iTCaMTd1FV38yHVamsrEykPvDJL6H8jKSPdwZ9u6WT6BcCqgQUmgNKIODOa8u80qwKCgFV0uvLGVvxAuPKnyersZyqxEIW51/AkrzzqU7IRQPN5NTtpMfhDfQ8vIFedRvpVb+R3KaKj2M44Mtjm7+YLfRmXXNPVjf0ZG1TT8rJwdnatiXTQJGU01f20lf20kfK6CNllMge+kgZifLJWWY1pLPT34u9ib0pTyrmcGIu5+ftIHv3PKjZ66yU1/+TnUDJyZCW16W/1XYFAlBb5ow5VelOqXkw4AzI63d0ZTXUOse2FvzVaWRk9IATZzkJ/vABqKt0Hg8fgMOVrZZVgjbDNz6AbgOOaTPaa/Fb4jefUVZdx50vruVwYzMZyQmkJ/tJT0ogPTnBTeh+0pIS3Nc+/XpGcgIpib52W8CVhxrYuu8Qpftq2bbvEKX7nfnSfYcoq/50EkyjjjG+TUzwb+RE33rGynqyObarjXdoPusCxXykxXwU6MNa7cNW7YEvIYkkv4+a+k/vkNKS/BTnplGcl0pRbhpFuakUZCbTHFD00D66lS2gsGI+vfctJKt+FwBViYVsyDiRzakj2Z/Yk/2J3Tng706TLwlVRXF7jnASb2ZyAj2zU+mZnULPTD99m7bSvXo1KWUrnF9BZWudf3yXIjSn5nE4qRuVvjzKNIftjRlsOpROaX0mVaRzUNM4SBoHNY1q0qgjCRB8An6fs/OZImu41Pc601lCojQzV8fyhJzFXMahPj8C+ETw+QS/OO/1+QS/+zyXgwzSrQxs3kw/3U6J7qBX0zZSA59cq1GfkElt1gDqcwbSnDcIvzaSUFVK0sFSkmu2kXxoL8InuafRn0Z1WjGVKcXsSymmLLGIPQm92enrRUUgk0ONAeoamznc2MzhhmZ+9aXRjOqd5dz6c/Mc5w5wW9+DhhpAoNdY59dicgb4kyEh6YjHlE/mmw67CX6bk+APlDq/LJraubgxt59zttqAM5ydTEpW2+tVbneuXl/6oHMMq9cJMPnrzv2qE5I6/6NVhfpqSEo/5q5PS/wm4h1qaKKmromkhE93CXy8EwkEnBbTjsXOP5L4nAmnWa3ioxmhWYXmgNCEcCitmAOZA6kmw/310tJN1fzxfH1TgMKslI+TfHFuKnnpSV3rvlGFA1tg09tOAtryzmcPVGcUQnYx5BQ7jy3zhw/Azg9g1wewZxU0uzu+1FzoNQ56j4OeY51trNkDNWVQ7T7W7P1kam7/BjvqS4SULCQlG5KzoP4g7N/s1HHCFXDiNcfcmvzM51C9G8rXOV1prR9r3Xs+Z/RwWsu5JU7yzOv3yWNaN+en0fFobnQ+z81znGnPSmg8/KmdZ4dSciC3L+T0dbqOckuc+dy+znd2cBdsesvpptnyntMNJn4onujsBAac4ST3HUtgwZ9h7b8BhWGfh8lfc7oug33GXCcs8RsTCoFmp+VYtR2qdjitvqpt7qO7rHWiTspwknvvE5yk0Wuck3C6miBUnR1ITZmzw6k/6Dy2TB8/P+jMq8LIL8GICyEx1ZOP4DMOV4I/CZLSQlPfkQLNzjGc5nrnsane+Q5alvmTnESfkt31MpsaYMci2PimszPYvdxZnpgGjYecg7YnzoKJXw3r8QdL/MZEgkDAOSularuT9PMHRc4ZTObY1VY4vzJK50H34c4B2eSMcEdlZ/UYExF8PsgsdCYTO9LzYdRFzhQFovhEWGOMMcfCEr8xxsQZS/zGGBNnwpL4ReQcEVknIhtF5I5wxGCMMfEq5IlfRPzAn4CZwHDgUhEZHuo4jDEmXoWjxT8R2Kiqm1W1AXgcuCAMcRhjTFwKR+LvDWxv9XyHu+xTROQGEVkiIkvKy+3OTcYYEywRe3BXVe9V1fGqOr6goCDc4RhjTMwIxwVcO4HiVs+L3GXtWrp0aYWIlB5jfflARadrRTbbhshg2xAZYmEbIDTb0bethSEfskFEEoD1wHSchL8YuExVV3tU35K2LlmOJrYNkcG2ITLEwjZAeLcj5C1+VW0SkZuB1wA/8IBXSd8YY8xnhWWsHlV9GXg5HHUbY0y8i9iDu0F0b7gDCALbhshg2xAZYmEbIIzbERXDMhtjjAmeeGjxG2OMacUSvzHGxJmYTvyxMBiciGwVkQ9FZLmIRMVtyETkAREpE5FVrZblicgbIrLBfcwNZ4ydaWcbfioiO93vYrmInBvOGDsjIsUi8raIrBGR1SJyi7s8ar6LDrYhar4LEUkRkUUissLdhp+5y/uJyEI3Pz0hIl24A3uQYorVPn53MLj1wJk4w0IsBi5V1TVhDewoichWYLyqRs0FKyJyClADPKSqI91lvwb2q+pd7k44V1VvD2ecHWlnG34K1Kjqb8IZW1eJSE+gp6p+ICKZwFLgQuBqouS76GAbLiFKvgsRESBdVWtEJBGYC9wCfBt4RlUfF5G/AitU9S+hiCmWW/w2GFyYqOq7wP4jFl8AzHbnZ+P880asdrYhqqjqblX9wJ2vBtbijIsVNd9FB9sQNdRR4z5NdCcFzgCecpeH9HuI5cTfpcHgooACr4vIUhG5IdzBHIdCVd3tzu8BovWmszeLyEq3Kyhiu0iOJCIlwAnAQqL0uzhiGyCKvgsR8YvIcqAMeAPYBFSqapO7SkjzUywn/lhxkqqOw7l/wU1uF0RUU6d/MRr7GP8CDADGAruBu8MbTteISAbwNPAtVT3Y+rVo+S7a2Iao+i5UtVlVx+KMTTYRGBrOeGI58R/1YHCRSFV3uo9lwLM4fzTRaK/bX9vSb1sW5niOmqrudf+BA8DfiYLvwu1Tfhp4VFWfcRdH1XfR1jZE43cBoKqVwNvAFCDHHbsMQpyfYjnxLwYGuUfOk4CvAC+EOaajIiLp7gEtRCQdOAtY1fG7ItYLwCx3fhbwfBhjOSYtydL1BSL8u3APKt4PrFXV37Z6KWq+i/a2IZq+CxEpEJEcdz4V54STtTg7gIvc1UL6PcTsWT0A7ile9/DJYHA/D3NIR0VE+uO08sEZV+mf0bANIvIYcBrOsLN7gZ8AzwFPAn2AUuASVY3Yg6ftbMNpOF0LCmwFbmzVVx5xROQk4D3gQyDgLv4+Th95VHwXHWzDpUTJdyEio3EO3vpxGttPqur/uP/fjwN5wDLgClWtD0lMsZz4jTHGfFYsd/UYY4xpgyV+Y4yJM5b4jTEmzljiN8aYOGOJ3xhj4owlfhM32hpx013e6WiVInK1iPzxKOv7fhfWeVBELupsPWOCyRK/iScPAue0sfwO4E1VHQS86T4Phk4TvzHhYInfxI0ORtzs6miVxSIyx/1l8JOWhSLynDuI3uqWgfRE5C4g1R0r/lF32VXuoGIrROThVuWeIiLvi8hma/2bUEjofBVjYl5XR6ucCIwEDgGLReQlVV0CXKuq+93L8ReLyNOqeoeI3OwOzIWIjAB+CExV1QoRyWtVbk/gJJyBu17gk6F6jfGEtfiNaaWT0SrfUNV9qnoYeAYnWQN8U0RWAAtwBgYc1MZ7zwD+1XJDnSOGSHhOVQPuTYKiYohkE90s8RvT9dEqj9whqIicBswApqjqGJwxV1KOsv7W47PIUb7XmKNmid+Yro9WeaZ7BlAqznGAeUA2cEBVD4nIUGByq/Ub3SGFAd4CLhaRbuCcSRTsjTCmqyzxm7jhjrg5HxgiIjtE5Dr3pbtwkvoGnNb7Xe0UsQhnXPiVwNNu//6rQIKIrHXft6DV+vcCK0XkUVVdDfwceMftFvotxoSJjc5pjDFxxlr8xhgTZyzxG2NMnLHEb4wxccYSvzHGxBlL/MYYE2cs8RtjTJyxxG+MMXHm/wNJ8PcD7VnVaQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZMPRX_YBE6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder.save_weights(\"encoder_mark.hdf5\")\n",
        "decoder.save_weights(\"decoder_ans.hdf5\")"
      ],
      "execution_count": 45,
      "outputs": []
    }
  ]
}